1. Теоретична частина
1.1. Огляд датасетів у кібербезпеці та постановка проблеми
	Для навчання моделей штучного інтелекту потрібно використовувати великі масиви навчальних даних, тобто фактично надати відповідній моделі яку ви навчаєте всі вже існуючі цифрові дані, включаючи тексти, зображення, відео, які люди створили у цифрову еру або те що встигли оцифрувати з доцифрової ери. Але вже зараз науковці заявляють про те, що у людства закінчуються навчальні дані – які є “паливом”, що забезпечують роботу потужних систем ШІ. Це може уповільнити розвиток моделей ШІ, особливо великих мовних моделей, і може навіть змінити траєкторію революції ШІ. [1]
Якість навчальних даних не менш важлива, ніж їхній обсяг. Наприклад, тексти з соціальних мереж або розмиті зображення легко отримати, але вони не завжди придатні для тренування високопродуктивних моделей [1].
Кібербезпека не стала виключенням і розробники відповідних інструментів та рішень для захисту інфраструктури, моніторингу та запобігання вторгнень активно імплементують ШІ модулі. Як і в інших сферах всі інструменти, які базуються на використанні штучного інтелекту будуть працювати настільки ефективно наскільки якісні та актуальні навчальні дані отримала система під час навчання.
	Отож, потрібно забезпечити постійний потік нових та актуальних датасетів, які будуть містити нові та актуальні методи атак, мають чітку класифікацію за рівнем загрози та додаткові метадані для підвищення якості навчання AI-моделей.
У кібербезпеці ранні відкриті набори на кшталт NSL-KDD чи CIC-IDS 2017 мали суттєві недоліки:
Застарілість, оскільки «типові» атаки 5–10-річної давності вже можуть бути неактуальними;
Невелика різноманітність (здебільшого DDoS, brute force, сканування) без охоплення складніших багатоступеневих атак;
Обмежене маркування: базова класифікація “атака vs. норма” без контексту (наприклад, таксономії MITRE ATT&CK).
Починаючи з 2020 року, ситуація дещо поліпшилася завдяки появі низки відкритих датасетів (Loghub, EDGAR Logs, AIT Intrusion Datasets, IoT-логів, CLUE-LDS), у яких:
Набагато ширший перелік сценаріїв (ІоT, хмари, корпоративні мережі, військові полігони тощо) [2]–[5].
Часто присутні мітки (labels) для задач виявлення аномалій, атак, класифікації ботів.
Використовуються уніфіковані формати (CSV, JSON), де вже проанонімізовані чи узгоджені поля [3], [6].
Найвідоміші приклади:
Loghub (2020–2023) – комплекс логів (системних, веб, кластерів Hadoop тощо) для тестування і порівняння алгоритмів аналізу [3].
SEC EDGAR Logs (з 2020) – публікація урядових веб-журналів доступу до фінансових звітів (щоквартально) [4].
AIT Intrusion Datasets (2020–2022) – реалістичні сценарії атак у невеликих мережах (IDS, syslog, DNS, VPN, e-mail) з чіткими мітками [5], [7].
CLUE-LDS (2022) – журнали активності користувачів у хмарі за 5 років, орієнтовані на UEBA (User and Entity Behavior Analytics) [6].
IoT-логів (CIC IoT 2022, ToN_IoT), що охоплюють трафік десятків пристроїв (камер, датчиків) з різними протоколами [8].
	Однак навіть ці набори не можуть вирішити проблему актуалізації логів, адже будь-який статичний датасет з часом “старіє”. У результаті нові типи атак (таких як уразливості в хмарних середовищах, складні багатоступеневі кампанії з lateral movement тощо) залишаються поза увагою. Наприклад, якщо завтра з’явиться нова вразливість у хмарних сховищах, треба швидко отримати журнали атак саме за цим вектором.
З огляду на потребу актуалізувати навчальні дані, виникає питання: Як швидко отримувати нові логи та маркувати їх згідно з актуальними сценаріями атак?
	Тут на допомогу приходить кіберполігон, який може слугувати лабораторією для симуляції реалістичних загроз. Якщо забезпечити грамотний процес автоматизованого й напівавтоматизованого маркування, зокрема із використанням MITRE ATT&CK, то кіберполігон перетворюється на динамічне джерело актуальних логів. Його реальний фокус полягає в тому, щоб:
Генерувати великий обсяг логів у контрольованих умовах, при цьому відображаючи різноманітні сценарії атак.
Впроваджувати системи маркування інтегрувати лог-сервери та SIEM-рішення, щоб із кожною новою сесією автоматично присвоювати подіям контекст та мітки.
Експортувати дані у формати, зручні для ШІ-моделей.
Таким чином, кіберполігони можуть бути джерелом релевантних і динамічних даних, завдяки яким моделі штучного інтелекту не лише отримають актуальні приклади різних векторів атак, а й зможуть безперервно оновлювати свої знання та ефективно адаптуватися до нових загроз. Саме це є ключовим фокусом роботи.
1.2 Кіберполігон як інфраструкта та джерело маркованих даних 
Сучасні кіберполігони мають широкий спектр функціональних можливостей, що робить їх важливими інструментами для навчання, тестування та дослідження. Вони розрізняються за призначенням, масштабованістю, інтерактивністю та можливістю інтеграції автоматизованих алгоритмів. У більшості джерел кіберполігони класифікують за функціоналом так:
Навчальні полігони – використовуються для підготовки фахівців із кібербезпеки та тестування їхніх навичок;
Тестові платформи – слугують для оцінки безпеки програмного забезпечення та інформаційних систем;
Дослідницькі полігони – застосовуються для аналізу нових загроз, розробки методів виявлення атак і випробування нових алгоритмів безпеки.
У сучасних кіберполігонах широко використовуються технології віртуалізації та хмарних обчислень, що дає змогу швидко адаптувати середовище під конкретні дослідження. Наприклад, у роботі "Cyber Ranges Implementation Methodology" зазначено, що "Кіберполігони можуть бути як віртуальними середовищами, так і фізичними лабораторіями, що відтворюють мережеву інфраструктуру компаній" [9].

	Рис 1. Типова архітектура кібер полігонів.
Зазвичай кіберполігони застосовуються для:
Тренування Red/Blue Team, коли учасники відпрацьовують напади та захисні дії (SOC-центри, SIEM-кореляції тощо).
Оцінювання готовності організацій до реальних інцидентів.
Відпрацювання процедур реагування (Incident Response).
З більшості публікацій випливає, що кіберполігони здебільшого використовуються для навчання спеціалістів (Red/Blue Team). Натомість маркування логів у контексті машинного навчання трапляється рідше. Завдяки можливості швидко змінювати сценарії атак у кіберполігоні, його можна перетворити на «лабораторію» з постійним отриманням нових даних для датасетів ШІ.
	1.3. Стисла характеристика наявних кіберполігонів та їх можливостей для генерації датасетів
Сучасні кіберполігони умовно поділяють на навчальні, військові, корпоративні й академічні. Навчальні платформи (HackTheBox, TryHackMe) розвивають навички пентестингу; військові (NATO CR) імітують складні бойові сценарії; корпоративні (IBM Cyber Range) зосереджені на тренуваннях SOC-фахівців; академічні (KYPO) використовуються здебільшого в науково-дослідній діяльності.
У більшості рішень переважає акцент на відпрацювання тактичних навичок, тоді як формування структурованих і ретельно позначених логів для ШІ залишається на другому плані. Тож у цій роботі ми приділяємо увагу саме можливості автоматизації збору й маркування логів у межах кіберполігону, щоби він став динамічним джерелом даних для LLM-моделей.
Такий підхід дозволить динамічно адаптувати методи аналізу загроз та автоматично оновлювати моделі ШІ відповідно до нових технік атак. Використання кіберполігонів у цьому контексті має потенціал стати постійним джерелом актуальних даних, оскільки під час їх експлуатації атакуюча сторона може застосовувати щоразу нові методики та інструменти. Це дає змогу в режимі реального часу записувати, аналізувати та використовувати ці дані для покращення ефективності захисту та раннього виявлення загроз.
Таким чином, у межах цього дослідження ми:
Оцінимо можливості кіберполігонів для автоматизованої генерації та маркування логів.
Дослідимо, як можна використовувати зібрані дані для навчання LLM-моделей.
Запропонуємо методологію збору та аналізу даних, яка забезпечить адаптивну та актуальну систему кіберзахисту.
Результати цієї роботи можуть суттєво розширити функціональність кіберполігонів, перетворивши їх з інструментів навчання на автоматизовані платформи для розвитку штучного інтелекту в кібербезпеці.
Найбільше нас цікавить саме KYPO Cyber Range Platform, бо це відкрита платформа, розроблена Масариковим університетом, яка дозволяє створювати масштабовані середовища для навчання та досліджень у сфері кібербезпеки. Платформа підтримує моделювання складних мережевих топологій та сценаріїв атак. [10]
1.4 Кіберполігон як джерело динамічних даних для навчання моделей ШІ.
Незважаючи на появу нових великих наборів логів (Loghub, AIT, IoT), вони залишаються статичними зрізами. Коли ж у реальному світі з’являються нові атаки (zero-day), статична вибірка втрачає актуальність. Кіберполігон натомість створює динамічний потік: за допомогою скриптів можна періодично “оновлювати” сценарії, відтворюючи сучасні техніки атаки, а потім знову збирати логи. Це дає:
Гнучке формування навчальних сетів: від різних видів веб-вразливостей (SQLi, RCE) до інсайдерських сценаріїв у корпоративній мережі.
Автоматизоване маркування (через контроль над атакуючими діями) – якщо відомо, коли саме почалася атака, можна проставити відповідні мітки без довгих ручних перевірок.
Онлайн-оновлення. По суті, модель ШІ можна тренувати або донавчати за свіжими логами, якщо полігон постійно генерує нові події.
Штучний інтелект має значний потенціал для виявлення та аналізу кіберзагроз, однак існує кілька ключових проблем:
Якість даних: Моделі ШІ вимагають великої кількості якісних даних для навчання. Збір, фільтрація та розмітка таких даних є складними завданнями.
Різноманітність атак: Реальні атаки постійно змінюються, що вимагає регулярного оновлення навчальних наборів даних.
Адаптивність моделей: Багато сучасних моделей не здатні швидко адаптуватися до нових типів атак, що знижує їхню ефективність у реальних умовах.
Кіберполігони з відповідним дизайном та інтегрованою системою збору логів (SIEM) здатні забезпечити всі ці умови. Саме тому використання полігонів можуть стати основою для подолання цих проблем, забезпечуючи платформу для автоматичного збору та маркування даних, необхідних для навчання моделей ШІ, що дозволить підвищити ефективність навчання моделей ШІ та оперативно адаптувати системи безпеки до нових загроз. 
1.5. Методи маркування даних 
Маркування даних є критично важливим етапом у підготовці наборів даних для навчання великих мовних моделей (LLM). Точне та ефективне маркування забезпечує моделям можливість розпізнавати та аналізувати патерни, що сприяє підвищенню точності та надійності їх прогнозів та зменшити хибно-позитивні спрацювання.
Автоматизоване маркування даних
Автоматизація процесу маркування дозволяє обробляти великі обсяги даних з мінімальним втручанням людини. Використання алгоритмів машинного навчання для автоматичного маркування логів може значно прискорити процес підготовки даних. Однак, для досягнення високої точності, такі системи потребують попереднього навчання на вже маркованих наборах даних.
Напівавтоматичне маркування з участю експертів
Комбінування автоматизованих методів з експертною оцінкою дозволяє підвищити якість маркування. Автоматизовані системи можуть виконувати первинне маркування, після чого експерти з кібербезпеки перевіряють та коригують результати. Такий підхід забезпечує баланс між ефективністю та точністю.
Використання сценаріїв для маркування
Створення детальних сценаріїв атак та захисних дій дозволяє заздалегідь визначити очікувані події та відповідні мітки для логів. Такий підхід забезпечує структуроване маркування даних та полегшує процес їх аналізу.
Автоматизоване маркування даних. Автоматизація процесу маркування дозволяє значно прискорити підготовку наборів даних та мінімізувати втручання людини. Автоматичне маркування може здійснюватися за допомогою:
Правил та сигнатур – система автоматично присвоює мітки логам, використовуючи заздалегідь визначені шаблони або політики розпізнавання подій.
Аномального аналізу – алгоритми машинного навчання аналізують логи та ідентифікують нетипову поведінку, яку можна позначити як потенційно шкідливу.
Потокової обробки даних – маркування відбувається в реальному часі, що дозволяє миттєво аналізувати нові загрози.
Автоматизоване маркування в кіберполігонах є ключовим аспектом для ефективного навчання моделей ШІ та забезпечує гнучкість у підготовці великих обсягів даних​
Використання сценаріїв для маркування
Використання детально розроблених сценаріїв атак дозволяє створювати попередньо марковані набори даних. Цей підхід включає:
Попередньо визначені мітки – кожна подія має чітке визначення у сценарії атаки або захисту.
Динамічне оновлення тегів – при зміні сценарію або додаванні нових атак система автоматично коригує маркування.
Правильне моделювання сценаріїв у кіберполігонах підвищує якість навчання моделей ШІ та дозволяє імітувати складні реальні ситуації​
Методи роботи з даними
Збір даних: автоматизація процесів моніторингу мережевого трафіку та системних логів.
Фільтрація: використання інструментів типу SIEM для вилучення тільки релевантних даних.
Розмітка: застосування технологій машинного навчання для створення контрольованих наборів даних.
У подальшому, в розділах 2 і 3, ми розглянемо, як саме ці методи маркування можуть реалізуватися в нашому інструменті (LogTagger) та як це може допомогти адаптуватися до динамічних сценаріїв атак.
1.6. Порівняльний аналіз існуючих методів маркування логів
	У результаті дослідження та пошуку існуючих методів їх умовно можна розділити на три основні категорії: маркування на основі правил, маркування за допомогою машинного навчання, гібридні методи. Кожен з варіантів ми описали наступним чином.
	Маркування на основі правил (rule-based labeling)
Цей метод базується на заздалегідь визначених правилах та сигнатурах, що використовуються для присвоєння міток логам. Основні характеристики:
Використовує фіксовані шаблони для визначення атак (наприклад, сигнатури IDS/IPS).
Добре працює для відомих загроз, але має низьку ефективність щодо нових атак.
Вимагає регулярного оновлення правил, щоб залишатися актуальним.
Приклад: Wazuh SIEM використовує правило на основі Sigma або YARA для автоматичного маркування інцидентів [12].
Маркування за допомогою машинного навчання (ML-based labeling)
ML-підходи використовують алгоритми, які аналізують історичні дані та знаходять шаблони, що відповідають атакам. Особливості цього підходу:
Використання кластеризації (K-Means, DBSCAN) для виявлення аномалій.
Використання наглядуваного навчання (Random Forest, XGBoost) для класифікації атак.
Потребує великих обсягів маркованих даних для ефективного навчання [13].
Приклад: Дослідження CIC-IDS2017 показало, що використання XGBoost для автоматичного маркування атак забезпечує точність понад 95% [14].
Гібридні методи (з використанням SIEM + ML)
Гібридний підхід поєднує rule-based маркування з можливостями машинного навчання, що дозволяє отримати найкращі результати.
Спочатку SIEM виконує первинне rule-based маркування.
Потім ML-модель додатково аналізує дані та уточнює мітки.
Такий підхід дозволяє підвищити точність маркування та зменшити кількість хибнопозитивних спрацювань.
Приклад: IBM QRadar використовує AI-підхід для автоматичного пріоритезації інцидентів, аналізуючи ймовірність реальної загрози [15].
Оцінка ефективності методів маркування логів є критичною для вибору оптимального підходу, що забезпечує баланс між точністю, швидкістю та адаптивністю до нових загроз. Для цього виконаємо порівняння виявлених методів (див. табл.1). Кожен із них має свої переваги та недоліки залежно від контексту використання та рівня автоматизації.
Метод маркування
Якість (Precision, Recall, F1-score)
Швидкість обробки
Адаптація до нових атак
Rule-based
Висока для відомих атак, низька для нових (≈85%)
Висока
Низька
ML-based
Висока для складних атак (>90%)
Середня
Висока
Гібридний
Найвища (≈95%)
Висока
Висока

Таблиця 1. Порівняльна таблиця ефективності методів
 	Існуючі методи маркування логів мають обмеження, які можуть впливати на точність та адаптивність систем кібербезпеки. Зокрема, автоматизовані методи, засновані виключно на машинному навчанні, потребують великої кількості якісно промаркованих даних для навчання. Використання даних, промаркованих іншими моделями машинного навчання, може призвести до накопичення помилок та зниження загальної точності системи. Щоб забезпечити високу якість маркування, ми плануємо розробити інструмент, який поєднує ручне маркування з допоміжними функціями машинного навчання. Такий підхід дозволить зберегти точність даних, мінімізуючи ризик накопичення помилок, та забезпечить ефективне навчання майбутніх моделей.









2. Моделювання
	2.1. Розробка методології маркування даних. 
	Розробка ефективної методології маркування даних є одним із ключових етапів підтвердження гіпотези та побудови нашого інструменту, призначеного для автоматичного та напівавтоматичного маркування логів і подій, що використовуються для навчання моделей штучного інтелекту в галузі кібербезпеки. Правильно визначений перелік тегів та міток напряму впливає на якість навчання моделей, адже від цього залежить точність класифікації та здатність алгоритмів до виявлення реальних кіберзагроз.
Першим кроком при розробці методології було визначення найважливіших типів інформації, що мають бути присутні у розмічених подіях. На основі аналізу сучасних практик маркування та реальних сценаріїв використання моделей ШІ в кібербезпеці було визначено перелік базових тегів, що мають найвищу цінність для навчання алгоритмів та наступного аналізу подій.
Основними критеріями, що вплинули на вибір тегів, стали:
Інформативність для алгоритмів (чітке розмежування атак від нормальної активності).
Можливість інтеграції зі стандартизованими схемами (MITRE ATT&CK).
Корисність для експертного аналізу (ручна перевірка та коригування).
Збереження контексту подій (групування та ланцюжки).
Таким чином, було сформовано наступний перелік рекомендованих міток (тегів):
True_Positive / False_Positive Ця мітка вказує на істинність спрацювання: подія дійсно відображає реальну атаку (True Positive) або є помилковим спрацюванням чи нешкідливою активністю (False Positive). Даний тип тегування обов’язковий для моделі, адже він визначає базову класифікацію на шкідливі та нормальні події. Для забезпечення точності моделі важливо використовувати узгоджений формат тегів (булевий або категоріальний) і забезпечити баланс класів, щоб уникнути зміщення результатів.
	Attack_Type (тип атаки) Поле визначає клас або категорію атаки, наприклад: "Brute force", "Phishing", "Malware infection", "Web exploit" тощо. Було обрано за аналогією до наборів даних, таких як CIC-IDS2017, і дозволяє як швидко фільтрувати інциденти, так і будувати ефективні моделі класифікації атак. В рамках методології було запропоновано створити фіксований словник Attack_Type, що відповідає потребам конкретної організації та інфраструктури, для забезпечення уніфікованості маркування.
MITRE Tactic/Technique Інтеграція тактик і технік з таксономії MITRE ATT&CK є обов'язковою складовою сучасних систем маркування через свою стандартизованість та широку підтримку в індустрії кібербезпеки. Було вирішено використовувати два поля: MITRE_Tactic (тактика) та MITRE_Technique (техніка), що дають змогу чітко позначати природу події за стандартом MITRE. Таке маркування дозволяє алгоритмам ефективніше узагальнювати і виявляти патерни атак.
Severity (критичність) Severity є стандартною практикою в SIEM-системах для визначення пріоритетності інцидентів. Ця мітка допомагає моделям ШІ навчатися розставляти пріоритети і швидко реагувати на найкритичніші загрози. Для забезпечення сумісності різних джерел було прийнято рішення використовувати єдину шкалу критичності, нормалізовану до 5-бальної системи (низький, середній, високий, критичний, інформаційний).
Event_Chain_ID (ID ланцюжка подій) Ця мітка є важливою для збереження контексту подій, адже більшість сучасних атак є багатокроковими і складаються з низки взаємопов’язаних дій. Використання єдиного ідентифікатора дозволяє об'єднувати події в логічні ланцюжки, що значно полегшує аналіз складних загроз і покращує якість навчання моделей, здатних виявляти взаємозв'язки та послідовності дій зловмисників.
Manual_Tag (ручна мітка) Останнім обов’язковим компонентом стало поле для ручного втручання експерта. Ця мітка дозволяє чітко вказувати, чи була подія переглянута і підтверджена аналітиком, або ж потребує подальшого розслідування. Такий підхід є важливим для активного навчання моделей, що дозволяє покращувати точність тегування шляхом систематичної роботи аналітика з проблемними випадками, які не можуть бути автоматично класифіковані з високою впевненістю.

Рис. 2. Обробка датасетів в інструменті маркування даних. 
Окрім зазначених вище, під час роботи можуть використовуватись додаткові мітки, такі як Indicator_ID, Attack_Group, Attack_Campaign, Confidence тощо, відповідно до потреб конкретних задач аналізу.
Таким чином, запропонована методологія маркування забезпечує мінімально необхідний і при цьому максимально корисний контекст для навчання моделей ШІ, значно покращуючи якість аналізу та детектування кіберзагроз.
	2.2. Вимоги та стандарти до датасетів для ефективного навчання ШІ
Якість навчання моделей ШІ напряму залежить від якості та актуальності даних. У сфері кібербезпеки існує кілька широко використовуваних відкритих датасетів журналів та мережевого трафіку
Щоб великі мовні моделі справді навчалися ефективно, ми виділили кілька ключових вимог:
Чітка структура й узгодженість тегів. Для того, щоб LLM чи інші AI-алгоритми могли правильно навчатися, ваш датасет повинен мати послідовну систему тегів і чітку структуру. Тобто якщо є поле “true_positive”, воно повинно скрізь мати однакову логіку (Boolean з однаковим значенням “True/False”), а не іноді “yes/no”, “1/0” або якісь інші варіації.
Збалансованість (і/або різноманітність) вибірки. У дослідженнях із відкритими датасетами часто наголошують, що моделі ШІ працюють краще, коли навчальний набір різноманітний за типами атак і “нормальних” подій. Якщо збирати логи лише з одного типу інцидентів (наприклад brute force), LLM може перенавчитися і не розуміти інших сценаріїв.
Контекст ланцюжків (chain of events) — врахування послідовності дій атакуючого. Дедалі частіше у тематичних статтях радять збирати ланцюжки подій (event chaining), щоб модель розуміла контекст атаки. Тому в полях, схожих на Event_Chain_ID, можна групувати пов’язані між собою логи: “спроба авторизації → ескалація привілеїв → рух у мережі”.
Використання MITRE ATT&CK чи інших таксономій для однозначного позначення технік, в такому випадку моделі штучного інтелекту зможуть краще зрозуміти патерн атаки.
Метадані про джерело та якість, це ще одна вимога, яку зустрічаємо у статтях — зберігати метадані, що вказують, звідки прийшли логи (яка SIEM, який час доби, тип системи) та наскільки якісно вони промарковані (manual vs. auto, рівень довіри). LLM може враховувати ці фактори, щоб не переоцінювати автоматичні теги, які можуть містити помилки.
Що стосується формату маркованих подій, то для зручності подальшої обробки та імпорту в моделі дані бажано зберігати у структурованому форматі. Найпоширеніші – це JSON та XML, які добре підходять для представлення логів разом із тегами. XML історично використовувався в багатьох системах (наприклад, формат IDMEF для інцидентів), але зараз частіше використовують JSON через його компактність і простоту інтеграції у стек сучасних мов програмування. Також згадується формат XAPI у контексті маркування логів​. Під XAPI можуть матися на увазі розширювані API-формати або стандарти типу STIX 2.0 (який є JSON-орієнтованим і використовується для передачі кіберрозвідданих, включаючи ATT&CK-теги). В будь-якому разі, важливо, щоб у вибраному форматі були закладені поля для тегів та довідкова інформація. Наприклад, у JSON можна зберігати подію як об’єкт (див. рис. 2).

Рис. 3. Приклад формату збереження тегів.
2.3. Імплементація маркування за MITRE ATT&CK
 У рамках LogTagger передбачено імплементацію маркування подій відповідно до бази знань MITRE ATT&CK. Кожна подія отримує відповідну мітку тактики і техніки, що значно підвищує якість та релевантність даних для навчання моделей штучного інтелекту.
Сьогодні існують спроби автоматизувати таке мапування. Наприклад, запропоновано моделі класифікації для Splunk-логів, що прогнозують відповідні ATT&CK техніки​. [16] Автоматизація не ідеальна, тому часто застосовується експертне правилове маркування: фреймворки на кшталт Sigma містять поля для ATT&CK-технік, якими аналітики доповнюють правила кореляції. В результаті, марковані таким чином логи (чи спрацьовування правил) прямо вказують, яку техніку ATT&CK було зафіксовано. Це суттєво полегшує подальший аналіз даних системою штучного інтелекту, адже надає узгоджену схему міток для навчання моделей. Згідно зі звітом компанії Cybero, більшість організацій мають достатньо логів, аби покрити до 94% технік з ATT&CK, але без належного мапування лише ~24% з них реально детектуються​. [17]
Тому впровадження систематичного тегування за ATT&CK закриває ці “прогалини” – кожна релевантна подія отримує свою категорію, і ШІ може навчатися розпізнавати їх за описовими ознаками, а не лише “сирими” даними.
2.4. Вибір сценарію формування навчальних наборів та логіки роботи інструменту
Під час поглибленого аналізу літератури й існуючих інструментів (як зазначено в розділах 1.1 та 1.5), виявилось, що у сфері навчання моделей штучного інтелекту для кібербезпеки можливі два підходи до збору та маркування логів:
Локальне маркування в межах кожної SIEM: У такій логіці кожна SIEM (скажімо, Wazuh чи Splunk) має власні плагіни або модулі, які виконують маркування (додають або уточнюють теги) безпосередньо всередині системи. Після цього логи експортуються у спільний формат (CSV, JSON) для подальшого навчання. Проте, коли потрібно працювати з кількома SIEM, це створює певні труднощі, адже потрібно підтримувати різні плагіни та узгоджувати структуру даних.
Універсальний “екстрактор та агрегатор”: Інший спосіб — спочатку отримувати логи з усіх можливих джерел (через API), уніфікувати їх (наприклад, приводити до одного формату поля Attack_Type, True_positive, Event_Chain_ID, а також загальних тегів MITRE ATT&CK).
Я вирішив зупинитися саме на підході “екстрактора”, адже він узгоджується з дослідницькою метою: створити єдину платформу для маркування, яку зручно масштабувати і під’єднувати до різних SIEM через API. З позиції навчання LLM це дозволяє сформувати великий, структурований датасет, що позитивно впливає на ефективне тренування моделей штучного інтелекту.
Я звернув увагу на те, що багато команд витрачають багато часу, щоб звести докупи логи з кількох різноманітних джерел та узгодити їхні поля. Тому я вирішив, що наш модуль LogTagger має бути саме тим “агрегатором”, який, незалежно від SIEM, “втягує” всі події через API та структурує їх у єдину схему. Завдяки цьому:
Спрощується підтримка: один набір правил та скриптів для маркування, а не кілька різних плагінів для кожної SIEM.
Легша масштабованість: достатньо написати один невеликий адаптер для нової SIEM.
Єдиний формат: це надзвичайно важливо для подальшого аналізу й навчання ШІ, інакше доведеться витрачати велику кількість часу на чистку та конвертацію.
Водночас у процесі ми усвідомили, що наше рішення більше орієнтоване на дослідження, а не на миттєве впровадження й продаж (адже збиратимемо та аналізуватимемо марковані логи, щоби перевірити, чи дійсно це покращить ефективність навчання LLM). 
2.5. Варіанти реалізації архітектури інструменту маркування датасетів
На цьому етапі нам потрібно визначити головні технічні пріоритети фінального інструменту, щоб краще розуміти, яка інфраструктура буде доцільна для реалізації.
 Перший варіант — інтегруватися безпосередньо в одну конкретну SIEM-систему (наприклад, Wazuh) на рівні дописування власних плагінів чи модулів. Це могло б виглядати як зручне рішення: коли логи відразу маркуються “всередині” SIEM, а потім передаються на навчання моделям ШІ. Проте виявилося, що такий варіант сильно прив’язаний до конкретної платформи та не дає можливості легко масштабуватись на інші системи.
Другий варіант, який ми вирішили втілити, — створити універсальний інструмент (LogTagger), який отримуватиме дані з будь-яких SIEM-систем через API, а далі доповнюватиме їх потрібними тегами та полями. Зрештою цей підхід виглядає більш гнучким і перспективним: якщо колись виникне потреба працювати не лише з Wazuh, а й, наприклад, зі Splunk чи іншим рішенням, ми не будемо кардинально змінювати наші внутрішні механізми.
Типові архітектурні рішення для систем маркування логів. Системи, що займаються збором та обробкою подій у реальному часі, зазвичай будуються за принципами event-driven (керовані подіями) та microservices. У контексті LogTagger, який має отримувати потік логів, аналізувати й маркувати їх, доречно виокремити кілька компонент: модуль збору (ingestion), модуль обробки/маркування та модуль збереження/видачі результатів. Застосування подієво-орієнтованої архітектури означає, що коли надходить новий запис логу, він генерує подію, яка запускає обробку у системі.
Щодо мікросервісності, то LogTagger можна розбити на кілька дрібніших сервісів: скажімо, окремий сервіс для парсингу та нормалізації входящих логів, окремий – для безпосереднього присвоєння міток (наприклад, застосування правил чи ML-моделі), і окремий – для збереження у базі. Така декомпозиція спрощує розробку і тестування (кожен компонент виконує одну задачу). Більшість сучасних систем обробки подій (Splunk, Elastic тощо) часто містять мікросервіси. 
У нашому проекті, враховуючи обмежені ресурси, ми можемо почати з монолітнішої реалізації (усі функції в одному застосунку), але з можливістю винесення їх, якщо знадобиться. Наприклад, правила кореляції (rule-based tagging) можуть жити як окремий JSON-конфігурація, а ML-модуль – окремо як сервіс, до якого основний LogTagger робить запит, щоб той спрогнозував мітки для події. Загальний досвід показує, що лог-системи краще працюють саме в розподіленій архітектурі: для високонавантажених випадків використовується декілька шарів – збирач агентів, брокер, процесор, база даних. Ми можемо орієнтуватися на архітектуру Elastic Stack: Filebeat → Logstash → Elasticsearch → Kibana. У ній Logstash відіграє роль процесора/тегувальника (виконує фільтрацію і додавання полів за правилами), причому ця фільтрація event-driven – як тільки отримано новий івент, він проходить через конвеєр фільтрів. У нашому LogTagger роль “Logstash” виконуватиме власне наш застосунок, що може бути розгорнутий як служба з API.
Використання ML для автоматизованого попереднього маркування. Передбачається, що LogTagger поєднуватиме правил-based і ML-based підходи. ML тут – це алгоритми, що навчені розпізнавати певні шаблони атак або аномалій у журналах. З переваг ML, то вона може знайти нетривіальні взаємозв’язки, які важко описати правилами. У нашому дизайні ML може виконувати роль попереднього маркувальника: модель прогнозує клас чи техніку атаки для події, але остаточне рішення може комбінуватися з правилами (гібридний підхід). Повна автоматизація можлива, але як ми розглядали раніше може накопичити помилки.
В нашій архітектурі ML-модель можна розгортати як окремий сервіс (наприклад, REST API, що отримує на вході подію і повертає ймовірності класів). Тоді LogTagger при обробці події спочатку викликає модель, додає її оцінку (наприклад, поле ML_predicted_label з відповідною технікою атаки)​. Далі поверх накладаються правила: якщо модель і правило збігаються, то мітка присвоюється, якщо розходяться – можна позначити подію для ручної перевірки. Такий гібридний підхід забезпечить збереження точності: автоматизація ML прискорює процес, але людина контролює якість​. Наприклад, ML може присвоїти мітку “NeedsReview” і пізніше людина скоригує.

Рис. 4. Схема інструменту маркування даних.
Отже, архітектура LogTagger передбачає асинхронну обробку подій (черги, реакція на подію) та модульність (мікросервіси для збору, правил, ML). Це забезпечить масштабованість системи під великий потік логів. Використання ж ML в маркуванні поступово вдосконалюватиме якість: спочатку модель працюватиме у парі з правилами, а з накопиченням даних – потенційно зможе брати на себе більше (наприклад, розпізнавати складні послідовності атак, де проста кореляція безсила). Вже зараз дослідження демонструють ефективність комбінованих методів – наприклад, автоматичне проставлення ATT&CK-тегів до правил IDS за допомогою GPT-3 показало обнадійливі результати​. [17] 

2.6. Методологія фільтрації та розмітки.
Журнали, особливо в Windows або мережевих обладнань, містять величезну кількість “шумових” подій – ті, що не несуть цінності для безпеки (наприклад, службові повідомлення про успішну роботу сервісу, періодичні системні завдання тощо). Критично важливо відфільтрувати несуттєві записи і практично ми будемо виконувати це на рівні SIEM. Більшість SIEM дозволяють налаштувати, які події індексувати, а які ігнорувати. Наприклад, якщо Wazuh генерує купу логів про успішні пінги чи про те, що служба X справно працює – можна написати правило, яке їх навіть не буде надсилати на сервер (або сервер їх буде пропускати). У Splunk можна налаштувати sourcetype фільтри, щоб певні події (по ключовому слову чи коду) просто не потрапляли в індекс. 
Також важливо застосовувати агрегацію та дедуплікацію. Часто шум створюють повторювані повідомлення. SIEM може виконувати агрегування: наприклад, замість сотні однакових повідомлень за хвилину – записати одне з лічильником 100. У нашому випадку, якщо LogTagger отримує вже агрегований алерт від SIEM (“100 failed logins from user X”), то він маркує один інцидент замість 100. Це добре. Якщо ні – ми самі можемо внести такий рівень: LogTagger може тримати тимчасовий буфер подій і, скажімо, згрупувати події за однаковими атрибутами в інтервалі часу, щоби мітити їх разом. Проте це ускладнює систему, тому на MVP етапі, ймовірно, покладаємось на можливості SIEM в цьому.
Практичний результат грамотної фільтрації – суттєве зменшення обсягу даних без втрати корисної інформації. Якщо наситити датасет шумом, модель може навчитися хибним паттернам, але при тому нам також важливо періодично формувати набори даних зі звичайною (нормальною) активністю. Це дозволить моделям краще розрізняти нормальну та аномальну поведінку, що сприятиме зменшенню кількості хибнопозитивних спрацювань.
Отже, на етапі формування датасету (тобто роботи LogTagger) потрібно передбачити після фільтрацію: навіть після маркування можна відкидати події, які отримали мітку “benign” або низький ризик. Це підвищить якість навчальної вибірки для ШІ.
Підсумовуючи: SIEM на полігоні – наш основний інструмент збору та первинного впорядкування логів. За рахунок налаштувань аудиту і фільтрів ми зменшимо шум приблизно до тих самих 20% даних, що дійсно варті уваги. Далі LogTagger працюватиме вже по відфільтрованих потоках, що збільшить його продуктивність і якість маркування. Цей багатоетапний процес (аудит → SIEM фільтри → LogTagger маркування/фільтри) відповідає реальним умовам в SOC, де аналітики теж поетапно зменшують кількість подій, щоб врешті отримати невелику кількість інцидентів, з якими можна працювати вручну.
Для кращого розуміння подальшої роботи архітектури збору та агрегування логів, нам потрібно виділити наступні технічні аспекти інтеграції з SIEM
API для взаємодії: SIEM (наприклад, Wazuh або Splunk) зазвичай має REST API чи інші механізми, завдяки яким LogTagger може періодично “витягувати” відповідні логи (з певним рівнем severity чи з конкретними полями). Це API також дає змогу синхронізувати статус: якщо лог позначено в SIEM як “resloved” чи “false_positive”, наш інструмент може, за необхідності, теж скоригувати свій запис.
Передача додаткових тегів назад у SIEM. У перспективі, якщо LogTagger виявить щось нове або внесе детальніше маркування, можна через той самий API повертати ці дані назад, щоб “збагачувати” SIEM. Наприклад, SIEM отримає від нас поле “Attack_Type=SQL Injection” чи “Detected rule=T1110” і збереже це у своїй базі кореляції.
Також ми передбачаємо потенційні проблеми з великим обсягом логів. У розгорнутому кіберполігоні кількість логів може створювати високе навантаження на продуктивність роботи та сховища даних за короткий проміжок часу. Потрібно слідкувати за продуктивністю SIEM та параметрами сховища.
Ефективність використання SIEM полягає в тому, що вона вже робить частину роботи з маркування: наприклад, Wazuh при спрацюванні правила проставляє кожному алерту рівень небезпеки, категорію (наприклад, “authentication_failure”) тощо. Splunk аналогічно має Common Information Model, який нормалізує події: назви полів приводяться до стандартних (user, src_ip, dest_ip і т.д.). Це нормалізування – перший крок маркування, який значно полегшує роботу LogTagger. Підключивши LogTagger до SIEM, ми можемо отримувати вже частково коректні дані: наприклад, разом з “Event ID 4625” ми отримаємо додатковий контекст - “Failed Logon”. SIEM також агрегує події: наприклад, кореляційне правило може генерувати один інцидент “Brute Force Attack” із зазначенням 50 невдалих входів за хвилину. Таким чином, SIEM знижує обсяг інформації, яку треба аналізувати, і надає контекст. Але часто правила покривають не все​, тому наш інструмент допомагатиме доповнити SIEM, але не замінити її. Фактично SIEM разом з інструментом маркування логів утворюють ефективну систему вибору датасетів (див. рис. 5). 
Рис. 5. Обробка даних в SIEM та LogTagger
Отже, запропонована методологія централізованого збору, фільтрації та маркування подій через інтеграцію SIEM із нашим інструментом LogTagger є цілісним рішенням, що відповідає реальним умовам роботи сучасних Security Operation Center (SOC). Це дозволяє нам максимально ефективно використовувати ресурси, отримувати структуровані та релевантні дані для подальшого навчання моделей ШІ і значно покращує якість детектування кіберзагроз.
2.7.  Вибір технологічного стеку для MVP
У межах цього проєкту було важливо максимально швидко отримати робочу «чернетку» системи, щоб перевірити гіпотезу про корисність ручного й автоматизованого маркування. 
Для LogTagger, який на першому етапі буде просто REST API (отримай лог – поверни мітки). Тому більш раціонально взяти Flask: легкий та простий. До того ж, Flask легше контейнеризувати і масштабувати в Kubernetes, якщо дійде до цього (бо він не містить складних залежностей). Django можна розглядати, якщо б ми планували повноцінний веб-інтерфейс для перегляду логів і керування, але наразі це не головна мета.
Щодо бази даних: нам треба сховище для промаркованих логів (і, можливо, для сирих теж). Два кандидати: PostgreSQL (реляційна СУБД) та MongoDB (NoSQL документо-орієнтована). В нашому випадку дані – це логи, які можуть бути досить різнорідними (одна колекція може містити і події Windows, і Linux, і мережеві – у них різні поля). Зберігати їх в одній SQL-таблиці означає мати дуже широку таблицю з купою NULL полів, або нормалізувати (винести спільне окремо, специфічне окремо), що ускладнює. У Mongo ми можемо все скласти в одну “колекцію events”, і кожен документ міститиме тільки свої поля. Приклад: документ для Windows несе поля event_id, user, а для мережевого – src_ip, dst_ip, протокол. Mongo це дозволяє без проблем. Для пошуку теж є інструменти – індекси по ключам.
Таким чином, схиляємося до MongoDB для сховища логів/міток, з таких міркувань:
Гнучкість схеми: легше додавати нові типи подій і тегів без міграцій.
Швидкість розробки: об’єкт, з яким працює Python (dict), майже без змін зберігається в Mongo (JSON), тобто мінімум перетворень.
Масштабування: якщо обсяг даних дуже виросте, Mongo можна шардувати чи реплікувати кластером, це вбудовано.
Тому я зупинився на зв’язці Python (Flask) + React, яку доповнив MongoDB для зберігання логів і тегів. Цей набір забезпечує простоту реалізації, достатню продуктивність на наших об’ємах та легку масштабованість у разі успіху проєкту. З таким стеком ми швидко отримаємо працюючий прототип LogTagger і зможемо сфокусуватись на функціональності (маркуванні логів), а не на обслуговуванні інфраструктурних нюансів.
Python добре підходить для побудови REST API, має багатий набір бібліотек і фреймворків. React у свою чергу дає змогу швидко створити дружній інтерфейс, де зручно працювати з таблицями, формами та динамічними списками. 
2.8. Інтеграція з форматами логів
Особливу увагу ми приділили сумісності нашої системи тегування з поширеними форматами логів безпеки. Для кожного з форматів розроблені відповідні механізми трансформації та збереження тегів:
Common Event Format (CEF). Для CEF ми використовуємо розширені поля (Extensions), де теги зберігаються з префіксом tag.: tag.attackType=sql_injection tag.truePosivite=true tag.severity=high tag.eventChainId=a1b2c3-001
Elastic Common Schema (ECS). В ECS теги інтегруються в структуру подій через спеціальний об'єкт tags та додаткові поля в event та threat об'єктах.
Для систем, що використовують власні JSON-формати, ми використали схему розширення, яка дозволяє вбудовувати наші теги без порушення оригінальної структури:
{
  "original_fields": { /*...*/ },
  "logtagger": {
    "attack_type": "brute_force",
    "true_positive": true,
    "severity": "medium",
    "event_chain_id": "a1b2c3-001",
    "manual_tags": ["suspicious_ip", "weekend_activity"]
  }
}
Також важливо додатково зазначити методологію узгодження тегів. Оскільки різні SIEM-системи можуть використовувати власні таксономії та формати, ми розробили методологію узгодження тегів, що включає:
Картографію тегів - таблицю відповідності між внутрішньою системою тегів LogTagger та тегами цільової SIEM
Двонаправлену трансформацію - конвертацію тегів у обох напрямках зі збереженням семантики
Метадані про походження тегу - зберігання інформації про джерело тегу для подальшого аудиту
Така методологія забезпечує безперервність аналітичного процесу та запобігає втраті цінної інформації при взаємодії з різними системами безпеки.
2.9.  Безпека зібраних датасетів
	Логи безпеки часто містять чутливу інформацію (імена користувачів, IP-адреси внутрішніх вузлів, деталі вразливостей). Тому система зберігання повинна забезпечувати шифрування даних на диску і при передачі. Рекомендовано використовувати сильні алгоритми шифрування, наприклад AES-256, для даних як в стані спокою (at rest), так і в транзиті​. 
Практично це означає, що ми повинні врахувати наступні аспекти:
Увімкнути шифрування на рівні СУБД або на рівні файлової системи для тієї директорії/диску, де зберігаються файли бази даних чи індексів.
Усі мережеві з’єднання (між агентами Wazuh і LogTagger, між LogTagger і OpenAI, між компонентами LogTagger) повинні проходити по захищеному протоколу HTTPS/TLS. Зокрема, виклики до Wazuh API (порт 55000) чи до Elastic (порт 9200) – з ввімкненим SSL.
API LogTagger (якщо він надає інтерфейс) теж має бути захищено HTTPS і вимагати аутентифікації.
Також варто ізолювати саму інфраструктуру інструменту для маркування подій безпеки – розмістити її в сегменті мережі з обмеженим доступом. Додатково необхідно маскувати чутливі дані при передачі в зовнішні сервіси: якщо лог містить, скажімо, паролі чи PII, краще видалити або захешувати такі дані перед відправкою в зовнішнього агенту штучного інтелекту. 
Загалом, дотримання принципу мінімізації даних у логах – не логувати надміру і відфільтровувати секрети – теж є частиною безпечної обробки.


3. Практична частина
3.1. Реалізація MVP
Для нашого проєкту, який ми умовно назвали "LogTagger", ми вирішили використати комбінацію Python та Flask для створення серверної частини, PostgreSQL для надійного зберігання даних та React.js для інтерактивного користувацького інтерфейсу. Такий стек технологій дозволив нам забезпечити швидке прототипування та поступове нарощування функціональності без необхідності переписувати архітектуру на пізніших етапах.
Основним компонентом серверної частини виступає модуль app.py, який відповідає за ініціалізацію Flask-додатку та реєстрацію маршрутів. Ми вирішили розділити функціональність на логічні модулі та виділити окремі файли для кожної групи функцій, що істотно покращило читабельність коду та спростило командну роботу. Такий підхід до організації коду дав нам змогу паралельно працювати над різними аспектами системи, не створюючи конфліктів при об'єднанні змін.
Файл models.py містить визначення моделей даних, необхідних для роботи системи. Ми свідомо відмовились від використання ORM-фреймворків на користь більш низькорівневої роботи з базою даних, що дозволило підвищити продуктивність у критичних сценаріях, зокрема при обробці великих обсягів логів. 
Клієнтська частина реалізована з використанням React.js, що забезпечило гнучкість та ефективність інтерфейсу. Головними компонентами інтерфейсу стали Dashboard для загального огляду, DataLabeling для маркування логів, ApiConfiguration для налаштування інтеграцій з SIEM та Configuration для загальних налаштувань. Такий набір компонентів дав нам можливість створити інтуїтивно зрозумілий інтерфейс, що відповідає потребам кінцевих користувачів — аналітиків безпеки.
Для забезпечення швидкого та безпроблемного розгортання системи ми розробили скрипт автоматизації bash.sh, який виконує всі необхідні кроки: від оновлення системи до застосування міграцій бази даних. Цей підхід дозволив мінімізувати ризики, пов'язані з ручним налаштуванням середовища, та забезпечив однакову конфігурацію у всіх екземплярах системи.





3.2. Робота з API SIEM 
Інтеграція з системами управління інформацією та подіями безпеки (SIEM) стала одним з ключових аспектів нашого дослідження. Ми зосередили увагу на розробці гнучкого модуля для взаємодії з Wazuh — відкритою платформою безпеки, яка надає широкі можливості для моніторингу та аналізу подій.
Наш підхід до інтеграції з Wazuh базувався на використанні його REST API, що дозволило нам ефективно отримувати інформацію про події безпеки. Ми створили спеціалізований модуль, який здійснює періодичні запити до API з урахуванням конфігураційних налаштувань. Такий механізм забезпечив можливість гнучкого налаштування частоти та параметрів запитів, що є критично важливим для різних сценаріїв використання системи.
При розробці модуля інтеграції ми приділили особливу увагу обробці помилок та відмовостійкості. Функціонал передбачає обробку різноманітних сценаріїв відмови API, включаючи тимчасову недоступність, проблеми з автентифікацією та перевищення лімітів запитів. Це рішення забезпечило стабільну роботу системи навіть у непередбачуваних умовах.


Розглянемо приклад інтеграції з Wazuh 
Отримання логів (GET /alerts): 
# Pseudocode
response = requests.get("https://wazuh-server:55000/alerts?status=open&limit=100", auth=token)
logs = response.json()
Аутентифікація: використовується Basic Auth або токен.
Збереження отриманих логів у MongoDB (колекція raw_logs), потім виклик rule-based і ML/LLM для їх маркування.
